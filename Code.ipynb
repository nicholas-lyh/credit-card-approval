{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, r2_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import random\n",
    "import math\n",
    "from statistics import mean, stdev\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11329, 23)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and show the data\n",
    "data = pd.read_csv(\"Bank_Credit_Cards.csv\", low_memory = False)\n",
    "data = data.drop(columns = ['CARD-DELIVERY','INCREASE-LIMIT-FLAG','INCREASE-LIMIT-DATE','NO-OF-CARDS','WRITE-OFF-DATE',\n",
    "                            'FREE-FEE-FLAG','CYCLE-CODE',' 4Y-AMT-CASH ','AT-ANNIV-DATE'])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([6745, 4584], dtype=int64))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove comma and blankspace\n",
    "data[\"AUTO-PAY\"] = data[\" OUT-BANK-ACCOUNT \"].str.replace(\" \",\"\")\n",
    "data[\"AUTO-PAY\"] = data[\"AUTO-PAY\"].str.replace(\",\",\"\")\n",
    "\n",
    "# Autopay = 1; NO autopay = 0\n",
    "data[\"AUTO-PAY\"] = data[[\"AUTO-PAY\"]].applymap(lambda x: 1 if len(x) > 9 else 0)\n",
    "\n",
    "data[\"AUTO-PAY\"].astype(\"category\")\n",
    "np.unique(data[\"AUTO-PAY\"], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([11226,   103], dtype=int64))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"OCCUPATION-CODE\"] = data[[\"OCCUPATION-CODE\"]].applymap(lambda x: 0 if x == 0 else 1)\n",
    "data[\"OCCUPATION-CODE\"].astype(\"category\")\n",
    "np.unique(data[\"OCCUPATION-CODE\"], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([3578, 7751], dtype=int64))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If Man, then equals 1; If Women, then equals 0\n",
    "data[\"SEX\"] = data[[\"SEX\"]].applymap(lambda x: 0 if x==\"F\" else 1)\n",
    "\n",
    "data[\"SEX\"].astype(\"category\")\n",
    "np.unique(data[\"SEX\"], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([10758,   571], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If no Black List, equals 0; Blacklisted, equals 1\n",
    "data[\"BLACK-LIST\"] = data[[\"BLACK-LIST-CODE\"]].applymap(lambda x: 0 if x==0 else 1)\n",
    "\n",
    "data[\"BLACK-LIST\"].astype(\"category\")\n",
    "np.unique(data[\"BLACK-LIST\"], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52,\n",
       "        53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69,\n",
       "        70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82], dtype=int64),\n",
       " array([  2,   9,  21,  38,  63,  90, 108, 151, 176, 194, 245, 265, 283,\n",
       "        287, 346, 406, 367, 418, 388, 409, 404, 389, 408, 411, 418, 427,\n",
       "        387, 370, 335, 327, 289, 262, 275, 260, 239, 254, 263, 196, 197,\n",
       "        110, 112, 130, 113, 118,  86,  67,  48,  46,  27,  20,  26,  19,\n",
       "          6,   4,   4,   1,   2,   3,   3,   3,   2,   1,   1], dtype=int64))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting Date data from integer to datetime \n",
    "# Randomly assigning a birthdate to those invalid value\n",
    "data[\"B-DATE\"] = data[[\"BIRTH-DATE\"]].applymap(lambda x: 19000101 if x < 19100000 or x > 19820000 else x)\n",
    "data[\"B-DATE\"] = pd.to_datetime(data[\"B-DATE\"], format='%Y%m%d')\n",
    "\n",
    "# Computing Age and assign random age to those does not have valid value\n",
    "from datetime import date\n",
    "  \n",
    "def calculateAge(birthDate):\n",
    "    today = date.today()\n",
    "    if birthDate.year != 1900: \n",
    "        # data was 20 years ago, age is thus deducted by 20\n",
    "        age = today.year - birthDate.year - ((today.month, today.day) < (birthDate.month, birthDate.day)) - 20\n",
    "    else: age = random.randint(18, 80)\n",
    "    return age\n",
    "\n",
    "data[\"AGE\"] = data[[\"B-DATE\"]].applymap(lambda x: calculateAge(x))\n",
    "np.unique(data[\"AGE\"], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.01587302, 0.03174603, 0.04761905, 0.06349206,\n",
       "        0.07936508, 0.0952381 , 0.11111111, 0.12698413, 0.14285714,\n",
       "        0.15873016, 0.17460317, 0.19047619, 0.20634921, 0.22222222,\n",
       "        0.23809524, 0.25396825, 0.26984127, 0.28571429, 0.3015873 ,\n",
       "        0.31746032, 0.33333333, 0.34920635, 0.36507937, 0.38095238,\n",
       "        0.3968254 , 0.41269841, 0.42857143, 0.44444444, 0.46031746,\n",
       "        0.47619048, 0.49206349, 0.50793651, 0.52380952, 0.53968254,\n",
       "        0.55555556, 0.57142857, 0.58730159, 0.6031746 , 0.61904762,\n",
       "        0.63492063, 0.65079365, 0.66666667, 0.68253968, 0.6984127 ,\n",
       "        0.71428571, 0.73015873, 0.74603175, 0.76190476, 0.77777778,\n",
       "        0.79365079, 0.80952381, 0.82539683, 0.84126984, 0.85714286,\n",
       "        0.87301587, 0.88888889, 0.9047619 , 0.92063492, 0.93650794,\n",
       "        0.95238095, 0.96825397, 1.        ]),\n",
       " array([  2,   9,  21,  38,  63,  90, 108, 151, 176, 194, 245, 265, 283,\n",
       "        287, 346, 406, 367, 418, 388, 409, 404, 389, 408, 411, 418, 427,\n",
       "        387, 370, 335, 327, 289, 262, 275, 260, 239, 254, 263, 196, 197,\n",
       "        110, 112, 130, 113, 118,  86,  67,  48,  46,  27,  20,  26,  19,\n",
       "          6,   4,   4,   1,   2,   3,   3,   3,   2,   1,   1], dtype=int64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing age values\n",
    "min_age = min(data[\"AGE\"])\n",
    "max_age = max(data[\"AGE\"])\n",
    "data[\"SCALED-AGE\"] = data[[\"AGE\"]].applymap(lambda x: (x-min_age)/(max_age-min_age))\n",
    "np.unique(data[\"SCALED-AGE\"], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 56,  65,  66,  67,  68,  69, 165, 166, 167, 168, 169, 265, 266,\n",
       "        267, 268, 269, 365, 366, 367, 368, 369, 465, 466, 467, 468, 469,\n",
       "        565, 566, 567, 568, 569, 665, 667, 668, 669, 756, 765, 766, 767,\n",
       "        768, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876],\n",
       "       dtype=int64),\n",
       " array([  1, 260, 290, 139,   2, 263, 196, 132, 151, 490, 285, 358, 189,\n",
       "        157, 203, 446, 464, 146, 120, 133,  74, 157, 256, 194,  87, 157,\n",
       "        110, 604, 203, 494, 592, 328, 306, 105, 182,   1, 169,  99,  92,\n",
       "        175, 329, 194, 257, 277, 220, 124, 258, 212, 174, 126, 116, 232],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"BRANCH-CODE\"].astype(\"category\")\n",
    "np.unique(data[\"BRANCH-CODE\"], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([      0,       1,  100000,  400000,  480000,  500000,  530000,\n",
       "         550000,  600000,  650000,  680000,  700000,  720000,  750000,\n",
       "         780000,  800000,  850000,  880000,  900000,  940000,  950000,\n",
       "        1000000]),\n",
       " array([    6,     1,     1,     1,     1,   489,     1,     2,    82,\n",
       "            6,     3,    94,     1,    10,     1,    72,    22,     1,\n",
       "           35,     2,    17, 10481], dtype=int64))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning SPENDING LIMIT and converting to integer\n",
    "data[\"SPENDING-LIMIT\"] = data[\" SPENDING-LIMIT \"].str.replace(\",\",\"\")\n",
    "data[\"SPENDING-LIMIT\"] = data[\"SPENDING-LIMIT\"].str.replace(\" \",\"\")\n",
    "data[\"SPENDING-LIMIT\"] = data[\"SPENDING-LIMIT\"].str.replace(\"-\",\"0\")\n",
    "data[\"SPENDING-LIMIT\"] = data[\"SPENDING-LIMIT\"].astype(str).astype(int)\n",
    "np.unique(data[\"SPENDING-LIMIT\"], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([      0,      11,      25, ..., 2019973, 2041930, 2082069])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning CURRENT BALANCE and converting to integer\n",
    "data[\"CURRENT-BALANCE\"] = data[\" CURRENT-BALANCE \"].str.strip(\" \")\n",
    "data[\"CURRENT-BALANCE\"] = data[\"CURRENT-BALANCE\"].apply(lambda x: 0 if len(x) > 9 else x)\n",
    "data[\"CURRENT-BALANCE\"] = data[\"CURRENT-BALANCE\"].str.replace(\"-\",\"0\")\n",
    "data[\"CURRENT-BALANCE\"] = data[\"CURRENT-BALANCE\"].astype(str)\n",
    "data[\"CURRENT-BALANCE\"] = data[\"CURRENT-BALANCE\"].str.replace(\",\",\"\")\n",
    "data[\"CURRENT-BALANCE\"] = data[\"CURRENT-BALANCE\"].apply(lambda x: 0 if x == \"nan\" else x)\n",
    "data[\"CURRENT-BALANCE\"] = data[\"CURRENT-BALANCE\"].astype(str).astype(int)\n",
    "np.unique(data[\"CURRENT-BALANCE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([      0,  100000,  200000,  320000,  330000,  498000,  500000,\n",
       "         535000,  600000,  700000,  800000,  850000,  900000,  930000,\n",
       "         950000,  969100,  970000,  998000, 1000000, 1020000, 1580000]),\n",
       " array([10880,     1,     1,     1,     1,     1,   160,     1,     8,\n",
       "            7,     4,     1,     3,     1,     2,     1,     1,     1,\n",
       "          252,     1,     1], dtype=int64))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning ONE YEAR CASH AMOUNT and converting to integer\n",
    "data[\"ONE-YEAR-CASH\"] = data[' OY-AMT-CASH '].str.strip(\" \")\n",
    "data[\"ONE-YEAR-CASH\"] = data[\"ONE-YEAR-CASH\"].str.replace(\"-\",\"0\")\n",
    "data[\"ONE-YEAR-CASH\"] = data[\"ONE-YEAR-CASH\"].str.replace(\",\",\"\")\n",
    "data[\"ONE-YEAR-CASH\"] = data[\"ONE-YEAR-CASH\"].astype(str).astype(int)\n",
    "np.unique(data[\"ONE-YEAR-CASH\"], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([      0,   83002,  100000,  115000,  120000,  125000,  130000,\n",
       "         140000,  150000,  160000,  170000,  180000,  200000,  205000,\n",
       "         220000,  230000,  250000,  298000,  300000,  330000,  330900,\n",
       "         350000,  360000,  370000,  400000,  450000,  460000,  471000,\n",
       "         480000,  485000,  490000,  492000,  493933,  495000,  496000,\n",
       "         497000,  499000,  500000,  520000,  530900,  540000,  550000,\n",
       "         565000,  590000,  593933,  596000,  597000,  600000,  605000,\n",
       "         610000,  617000,  640000,  650000,  665000,  670000,  680000,\n",
       "         685000,  700000,  720000,  750000,  780000,  790000,  795000,\n",
       "         800000,  845000,  847092,  850000,  860000,  880000,  890000,\n",
       "         900000,  917000,  920000,  930000,  930900,  931000,  940000,\n",
       "         950000,  960000,  969000,  969100,  970000,  970900,  975000,\n",
       "         976000,  978000,  980000,  980900,  981000,  985000,  988000,\n",
       "         989000,  990000,  990900,  991000,  994751,  995000,  995500,\n",
       "         996000,  996262,  996589,  997000,  998000,  999000,  999900,\n",
       "        1000000, 1005000, 1010000, 1011000, 1015000, 1016000, 1019000,\n",
       "        1020000, 1020900, 1025000, 1030000, 1030900, 1033000, 1040000,\n",
       "        1050000, 1060000, 1070000, 1072000, 1080000, 1092000, 1099000,\n",
       "        1100000, 1105000, 1115000, 1130900, 1139000, 1140000, 1150000,\n",
       "        1151427, 1170000, 1185000, 1200000, 1250000, 1300000, 1350000,\n",
       "        1370000, 1380000, 1400000, 1420000, 1450000, 1490000, 1500000,\n",
       "        1514000, 1541000, 1550000, 1560000, 1570000, 1593000, 1600000,\n",
       "        1665000, 1700000, 1747000, 1790000, 1850000, 1880000, 1900000,\n",
       "        1950000, 1985000, 1990000, 2000000, 2020000, 2100000, 2200000,\n",
       "        2340000, 3070000]),\n",
       " array([6565,    1,   40,    1,    1,    1,    1,    1,    9,    1,    1,\n",
       "           2,   20,    1,    1,    1,    6,    1,   20,    1,    1,    3,\n",
       "           1,    1,   21,    3,    1,    1,    4,    1,    9,    1,    3,\n",
       "           1,    3,    3,    2,  248,    2,    1,    1,    7,    1,    3,\n",
       "           2,    2,    2,   79,    1,    1,    1,    1,   16,    1,    1,\n",
       "           1,    1,   60,    1,   16,    1,    1,    1,   58,    1,    1,\n",
       "          18,    2,    1,    3,   62,    1,    2,    4,    1,    1,    3,\n",
       "          55,    1,    1,    1,    8,    1,    1,    1,    1,   20,    2,\n",
       "           1,    1,    2,    2,   29,    1,    1,    1,   11,    1,    2,\n",
       "           1,    1,    6,    5,    7,    1, 3666,    1,    5,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    9,    2,\n",
       "           2,    1,    1,    1,    2,   38,    1,    1,    1,    1,    1,\n",
       "           6,    1,    1,    1,   10,    4,    4,    3,    1,    1,    2,\n",
       "           1,    1,    1,    6,    1,    1,    1,    1,    1,    1,    2,\n",
       "           1,    1,    1,    1,    1,    1,    1,    2,    1,    1,    9,\n",
       "           1,    1,    1,    1,    1], dtype=int64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning PRESENT YEAR CASH AMOUNT and converting to integer\n",
    "data[\"PRESENT-YEAR-CASH\"] = data[' PY-AMT-CASH '].str.strip(\" \")\n",
    "data[\"PRESENT-YEAR-CASH\"] = data[\"PRESENT-YEAR-CASH\"].str.replace(\"-\",\"0\")\n",
    "data[\"PRESENT-YEAR-CASH\"] = data[\"PRESENT-YEAR-CASH\"].str.replace(\",\",\"\")\n",
    "data[\"PRESENT-YEAR-CASH\"] = data[\"PRESENT-YEAR-CASH\"].astype(str).astype(int)\n",
    "np.unique(data[\"PRESENT-YEAR-CASH\"], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0, 12, 21, 33, 44, 55, 65, 75, 85, 95]),\n",
       " array([1067, 1842, 1407,  676, 1299,  938,  712,    2, 3385,    1],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"ACCT-STATUS\"] = data[\"ACCOUNT-STATUS\"].str.replace(\"0S\",\"75\")\n",
    "data[\"ACCT-STATUS\"] = data[\"ACCT-STATUS\"].str.replace(\"NE\",\"85\")\n",
    "data[\"ACCT-STATUS\"] = data[\"ACCT-STATUS\"].str.replace(\"ME\",\"95\")\n",
    "data[\"ACCT-STATUS\"] = data[\"ACCT-STATUS\"].astype(int)\n",
    "np.unique(data[\"ACCT-STATUS\"], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-de579e172983>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"BLACK-LIST-DATE\"][i] = 20031231 - data[\"BLACK-LIST-DATE\"][i]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.50629346, 0.50631839, 0.50639316, 0.50641809,\n",
       "        0.50644301, 0.50649286, 0.50659256, 0.50661748, 0.50664241,\n",
       "        0.50666733, 0.5084619 , 0.50848683, 0.50851175, 0.5086613 ,\n",
       "        0.50871115, 0.50873607, 0.50881085, 0.50888562, 0.50898532,\n",
       "        0.50901024, 0.50903517, 0.50908502, 0.50915979, 0.50920964,\n",
       "        0.51095436, 0.51105406, 0.51107899, 0.51110391, 0.51112884,\n",
       "        0.51115376, 0.51125346, 0.51127838, 0.51130331, 0.51132823,\n",
       "        0.51140301, 0.51142793, 0.51145286, 0.51147778, 0.51157748,\n",
       "        0.5116024 , 0.51165225, 0.51349667, 0.5135216 , 0.51354652,\n",
       "        0.51357145, 0.51359637, 0.51367114, 0.51369607, 0.51372099,\n",
       "        0.51384562, 0.51387054, 0.51389547, 0.51394532, 0.51402009,\n",
       "        0.51404501, 0.51406994, 0.51419456, 0.51593928, 0.51596421,\n",
       "        0.51598913, 0.51601406, 0.51608883, 0.51611376, 0.51613868,\n",
       "        0.51616361, 0.51633808, 0.516363  , 0.51643778, 0.5164627 ,\n",
       "        0.51651255, 0.51661225, 0.51663717, 0.51863114, 0.51875576,\n",
       "        0.51890531, 0.51895516, 0.51898009, 0.51907978, 0.51910471,\n",
       "        0.51912963, 0.51915456, 0.5210239 , 0.52104883, 0.52119837,\n",
       "        0.5212233 , 0.52127315, 0.52134792, 0.52149747, 0.52154732,\n",
       "        0.52157224, 0.52349144, 0.52351636, 0.52361606, 0.52364099,\n",
       "        0.52371576, 0.52381546, 0.52386531, 0.52389023, 0.52401486,\n",
       "        0.52403978, 0.5240647 , 0.52413948, 0.5241644 , 0.52590912,\n",
       "        0.52593405, 0.52595897, 0.52603375, 0.52605867, 0.5260836 ,\n",
       "        0.52610852, 0.52625807, 0.52638269, 0.52645747, 0.52648239,\n",
       "        0.74781287, 0.74796241, 0.74798734, 0.74813689, 0.74818674,\n",
       "        0.74833628, 0.74836121, 0.74838613, 0.75025548, 0.7504798 ,\n",
       "        0.75050472, 0.75060442, 0.75062935, 0.75077889, 0.75080382,\n",
       "        0.75085367, 0.75092844, 0.75095337, 0.75097829, 0.75282271,\n",
       "        0.75302211, 0.75337105, 0.75344583, 0.75526532, 0.7553401 ,\n",
       "        0.75543979, 0.75551457, 0.75563919, 0.75568904, 0.75586351,\n",
       "        0.75596321, 0.75775778, 0.75788241, 0.75793225, 0.75825627,\n",
       "        0.7582812 , 0.75840582, 0.75843075, 0.76032502, 0.76069889,\n",
       "        0.76079858, 0.76084843, 0.76279255, 0.76281748, 0.76289225,\n",
       "        0.7629421 , 0.76296702, 0.7631415 , 0.7632412 , 0.76326612,\n",
       "        0.76523516, 0.76533486, 0.76548441, 0.76550933, 0.76553426,\n",
       "        0.76565888, 0.76782732, 0.76797687, 0.76812642, 0.77515516,\n",
       "        0.99755739, 0.99997508, 1.        ]),\n",
       " array([10758,     1,     1,     6,     2,     7,    12,     2,     2,\n",
       "            1,     8,     4,     2,     4,     4,     3,     2,     1,\n",
       "            5,     4,     2,     2,     3,     4,     3,     3,     1,\n",
       "            3,     2,     4,     8,     3,     3,     4,     2,     2,\n",
       "            5,     2,     5,     1,     1,     3,     3,     2,    17,\n",
       "           31,    14,    12,     5,     2,     4,     1,     6,     3,\n",
       "            1,     7,     1,     2,     3,     2,     3,     3,     5,\n",
       "            5,     2,     8,     3,     1,     5,     1,     7,     1,\n",
       "            1,     3,     1,     4,     1,     4,     2,     1,     1,\n",
       "            3,     2,     1,     5,     1,     3,     4,     4,     1,\n",
       "            1,     1,     3,     1,     3,     1,     5,     2,     3,\n",
       "            3,     1,     3,     1,     2,     2,     1,     6,     1,\n",
       "            1,     3,     4,     6,     2,     3,    15,     3,     2,\n",
       "            2,     2,     1,     3,     4,    46,     2,     1,     1,\n",
       "            1,     1,     1,     1,     1,     2,     3,     1,     5,\n",
       "            2,     2,     1,     1,     3,     1,     2,     1,     1,\n",
       "            1,     1,     2,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     2,     3,     7,     3,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            2,    13,     2,     2,     1,     1,     1], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(data[\"BLACK-LIST-DATE\"])):\n",
    "    if data[\"BLACK-LIST-DATE\"][i] != 0 and data[\"BLACK-LIST-DATE\"][i] > 1:\n",
    "        data[\"BLACK-LIST-DATE\"][i] = 20031231 - data[\"BLACK-LIST-DATE\"][i]\n",
    "        pass\n",
    "max_num = max(data[\"BLACK-LIST-DATE\"])\n",
    "data[\"BLACK-LIST-DATE\"] = data[[\"BLACK-LIST-DATE\"]].applymap(lambda x: x /(max_num))\n",
    "np.unique(data[\"BLACK-LIST-DATE\"], return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([ 1206, 10123], dtype=int64))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BUCKET: 1 = GOOD customer; 0 = BAD customer\n",
    "data[\"ZERO-ONE-BUCKET\"] = data[[\"BUCKET\"]].applymap(lambda x: 1 if x == 1 or x == 0 else 0)\n",
    "data[\"ZERO-ONE-BUCKET\"].astype(\"category\")\n",
    "np.unique(data[\"ZERO-ONE-BUCKET\"], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-7, -6, -5, -4, -3, -2,  0], dtype=int64),\n",
       " array([ 306,   57,  120,  267,  807, 1155, 8617], dtype=int64))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"ALL-MAX-BUCKET\"] = data[[\"ALL-MAX-BUCKET\"]].applymap(lambda x: -x)\n",
    "np.unique(data[\"ALL-MAX-BUCKET\"], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = [' ACC-AQCCOUNT-NO ', 'MEMBER-SINCE',\n",
    "                            ' AVG-PAYMENTS ',' AVG-BALANCES ','LAST-TRX-DATE',\n",
    "                            ' OUT-BANK-ACCOUNT ',' OY-AMT-CASH ', ' PY-AMT-CASH ', 'AGE',\n",
    "                            ' YTD-AMT-CASH ','PY-MAX-BUCKET',' CURRENT-BALANCE ',\n",
    "                            'ACCOUNT-STATUS','BIRTH-DATE','B-DATE','BLACK-LIST-CODE',\n",
    "                            'ATTRITION-REASON', ' SPENDING-LIMIT '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11329 entries, 0 to 11328\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   SEX                11329 non-null  int64  \n",
      " 1   OCCUPATION-CODE    11329 non-null  int64  \n",
      " 2   BLACK-LIST-DATE    11329 non-null  float64\n",
      " 3   BUCKET             11329 non-null  int64  \n",
      " 4   YTD-MAX-BUCKET     11329 non-null  int64  \n",
      " 5   ALL-MAX-BUCKET     11329 non-null  int64  \n",
      " 6   BRANCH-CODE        11329 non-null  int64  \n",
      " 7   AUTO-PAY           11329 non-null  int64  \n",
      " 8   BLACK-LIST         11329 non-null  int64  \n",
      " 9   SCALED-AGE         11329 non-null  float64\n",
      " 10  SPENDING-LIMIT     11329 non-null  int32  \n",
      " 11  CURRENT-BALANCE    11329 non-null  int32  \n",
      " 12  ONE-YEAR-CASH      11329 non-null  int32  \n",
      " 13  PRESENT-YEAR-CASH  11329 non-null  int32  \n",
      " 14  ACCT-STATUS        11329 non-null  int32  \n",
      " 15  ZERO-ONE-BUCKET    11329 non-null  int64  \n",
      "dtypes: float64(2), int32(5), int64(9)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_APP = data[[\"AUTO-PAY\", \"OCCUPATION-CODE\", \"SCALED-AGE\", \"BLACK-LIST\",\n",
    "              \"SEX\", \"BRANCH-CODE\"]].values\n",
    "X_BS = data[[\"YTD-MAX-BUCKET\", \"ONE-YEAR-CASH\",\"SPENDING-LIMIT\",\"PRESENT-YEAR-CASH\",\n",
    "             \"BLACK-LIST-DATE\", \"CURRENT-BALANCE\", \"ACCT-STATUS\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_01 = data[\"ZERO-ONE-BUCKET\"].values\n",
    "y_BP = data[\"ALL-MAX-BUCKET\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPLICATION SCORING - ZERO ONE CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.89      0.94      3399\n",
      "\n",
      "    accuracy                           0.89      3399\n",
      "   macro avg       0.50      0.45      0.47      3399\n",
      "weighted avg       1.00      0.89      0.94      3399\n",
      "\n",
      "Accuracy Score: 89.3498%\n",
      "Square root of Sensitivity and Specificity: 0.0000%\n",
      "Average P/L: -3.0056%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "specificity = []\n",
    "sensitivity = []\n",
    "pnl = []\n",
    "profit = []\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits = 10, test_size=0.3, random_state=42)\n",
    "sss.get_n_splits(X_APP, y_01)\n",
    "\n",
    "for train_index, test_index in sss.split(X_APP, y_01):\n",
    "    \"\"\" Splitting data into 10 splits and applying Logistic Regression \"\"\"\n",
    "    X_train, X_test = X_APP[train_index], X_APP[test_index]\n",
    "    y_train, y_test = y_01[train_index], y_01[test_index]\n",
    "    lr = LogisticRegression(max_iter = 50).fit(X_train,y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    pnl = []\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        \"\"\" To calculate average profit / loss             \n",
    "            1 = Good Customer; 0 = Bad Customer\"\"\"\n",
    "        if y_pred[i] == 1 and y_test[i] == 1:\n",
    "            pnl.append(0.02),\n",
    "        elif y_pred[i] == 1 and y_test[i] == 0:\n",
    "            pnl.append(-0.45),\n",
    "        pass\n",
    "        \n",
    "    \"\"\" To evaluate the model \"\"\"\n",
    "    profit.append(mean(pnl))\n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity.append(tn / (tn+fp))\n",
    "    sensitivity.append(recall_score(y_test, y_pred))\n",
    "    \n",
    "ans = []\n",
    "for i in range(len(sensitivity)):\n",
    "    ans.append(math.sqrt(specificity[i]*sensitivity[i]))\n",
    "\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(\"Accuracy Score: {:.4f}%\".format(mean(accuracy)*100)),\n",
    "print(\"Square root of Sensitivity and Specificity: {:.4f}%\".format(mean(ans)*100)),\n",
    "print(\"Average P/L: {:.4f}%\".format(mean(profit)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.09      0.08       297\n",
      "           1       0.91      0.89      0.90      3102\n",
      "\n",
      "    accuracy                           0.82      3399\n",
      "   macro avg       0.49      0.49      0.49      3399\n",
      "weighted avg       0.84      0.82      0.83      3399\n",
      "\n",
      "Accuracy Score: 82.7626%\n",
      "Square root of Sensitivity and Specificity: 27.0252%\n",
      "Average P/L: -3.0211%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 20)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits = 10, test_size = 0.3, random_state = 42)\n",
    "sss.get_n_splits(X_APP, y_01)\n",
    "\n",
    "accuracy = []\n",
    "specificity = []\n",
    "sensitivity = []\n",
    "pnl = []\n",
    "profit = []\n",
    "\n",
    "for train_index, test_index in sss.split(X_APP, y_01):\n",
    "    \"\"\" Splitting data and loading Tree Classifier \"\"\"\n",
    "    X_train, X_test = X_APP[train_index], X_APP[test_index]\n",
    "    y_train, y_test = y_01[train_index], y_01[test_index]\n",
    "    tree.fit(X_train, y_train)\n",
    "    y_pred = tree.predict(X_test)\n",
    "    pnl = []\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        \"\"\" assigning profit or loss values to predictions \"\"\"\n",
    "        if y_pred[i] == 1 and y_test[i] == 1:\n",
    "            pnl.append(0.02),\n",
    "        elif y_pred[i] == 1 and y_test[i] == 0:\n",
    "            pnl.append(-0.45),\n",
    "        pass\n",
    "    \n",
    "    \"\"\" evaluating model \"\"\"\n",
    "    profit.append(mean(pnl))\n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity.append(tn / (tn+fp))\n",
    "    sensitivity.append(recall_score(y_test, y_pred))\n",
    "    \n",
    "ans = []\n",
    "for i in range(len(sensitivity)):\n",
    "    ans.append(math.sqrt(specificity[i]*sensitivity[i]))\n",
    "\n",
    "    \n",
    "print(classification_report(y_pred, y_test))\n",
    "print(\"Accuracy Score: {:.4f}%\".format(mean(accuracy)*100)),\n",
    "print(\"Square root of Sensitivity and Specificity: {:.4f}%\".format(mean(ans)*100)),\n",
    "print(\"Average P/L: {:.4f}%\".format(mean(profit)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.08      0.04       132\n",
      "           1       0.96      0.89      0.93      3267\n",
      "\n",
      "    accuracy                           0.86      3399\n",
      "   macro avg       0.50      0.49      0.48      3399\n",
      "weighted avg       0.92      0.86      0.89      3399\n",
      "\n",
      "Accuracy Score: 86.1548%\n",
      "Square root of Sensitivity and Specificity: 18.9725%\n",
      "Average P/L: -3.0169%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "accuracy = []\n",
    "specificity = []\n",
    "sensitivity = []\n",
    "pnl = []\n",
    "profit = []\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators= 50, max_depth = 50)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits = 10, test_size = 0.3, random_state = 42)\n",
    "sss.get_n_splits(X_APP, y_01)\n",
    "\n",
    "for train_index, test_index in sss.split(X_APP, y_01):\n",
    "    \"\"\" Splitting data and loading Random Forest Classifier \"\"\"\n",
    "    X_train, X_test = X_APP[train_index], X_APP[test_index]\n",
    "    y_train, y_test = y_01[train_index], y_01[test_index]\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    pnl = []\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        \"\"\" loading profit or loss values to predictions \"\"\"\n",
    "        if y_pred[i] == 1 and y_test[i] == 1:\n",
    "            pnl.append(0.02),\n",
    "        elif y_pred[i] == 1 and y_test[i] == 0:\n",
    "            pnl.append(-0.45),\n",
    "        pass\n",
    "    \n",
    "    \"\"\" evaluating model \"\"\"\n",
    "    profit.append(mean(pnl))\n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity.append(tn / (tn+fp))\n",
    "    sensitivity.append(recall_score(y_test, y_pred))\n",
    "\n",
    "ans = []\n",
    "for i in range(len(sensitivity)):\n",
    "    ans.append(math.sqrt(specificity[i]*sensitivity[i]))\n",
    "\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(\"Accuracy Score: {:.4f}%\".format(mean(accuracy)*100)),\n",
    "print(\"Square root of Sensitivity and Specificity: {:.4f}%\".format(mean(ans)*100)),\n",
    "print(\"Average P/L: {:.4f}%\".format(mean(profit)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPLICATION SCORING - BUCKET PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         0\n",
      "          -6       0.00      0.00      0.00         0\n",
      "          -5       0.00      0.00      0.00         0\n",
      "          -4       0.00      0.00      0.00         0\n",
      "          -3       0.00      0.00      0.00         0\n",
      "          -2       0.00      0.00      0.00         0\n",
      "           0       1.00      0.76      0.86      3399\n",
      "\n",
      "    accuracy                           0.76      3399\n",
      "   macro avg       0.14      0.11      0.12      3399\n",
      "weighted avg       1.00      0.76      0.86      3399\n",
      "\n",
      "The square root of Specificity and Sensitivity is 0.0000%\n",
      "The average P/L is -0.7843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=4242)\n",
    "sss.get_n_splits(X_APP, y_BP)\n",
    "\n",
    "specificity = []\n",
    "sensitivity = []\n",
    "pnl = []\n",
    "profit = []\n",
    "\n",
    "for train_index, test_index in sss.split(X_APP, y_BP):\n",
    "    \"\"\" Splitting data into 10 splits and applying Linear Regression \"\"\"\n",
    "    X_train, X_test = X_APP[train_index], X_APP[test_index]\n",
    "    y_train, y_test = y_BP[train_index], y_BP[test_index]\n",
    "    lr = LogisticRegression(C = 0.5, max_iter = 500, solver = \"saga\").fit(X_train,y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    pred_proba = lr.predict_proba(X_test)\n",
    "    recall = recall_score(y_pred, y_test, average = \"weighted\")\n",
    "    \n",
    "    \"\"\" Calculating sensitivity \"\"\"\n",
    "    actually_good = 0\n",
    "    for i in y_test:\n",
    "        if i >= -1:\n",
    "            actually_good = actually_good + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_good = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] >= -1 and y_test[i] >= -1:\n",
    "            predict_actual_good = predict_actual_good + 1\n",
    "            pass\n",
    "    goodness = predict_actual_good / actually_good\n",
    "    sensitivity.append(goodness)\n",
    "\n",
    "    \"\"\" Calculating Specificity\"\"\"\n",
    "    actually_bad = 0\n",
    "    for i in y_test:\n",
    "        if i < -1:\n",
    "            actually_bad = actually_bad + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_bad = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] < -1 and y_test[i] < -1:\n",
    "            predict_actual_bad = predict_actual_bad + 1\n",
    "            pass\n",
    "    badness = predict_actual_bad / actually_bad\n",
    "    specificity.append(badness)\n",
    "    \n",
    "    \"\"\" Calculating average profit / loss \"\"\"\n",
    "    pnl = []\n",
    "    for i in range(len(y_pred)):\n",
    "        \"\"\" Assigning profit or loss values to predictions \"\"\"\n",
    "        if y_pred[i] == 0:\n",
    "            pnl.append(y_test[i])\n",
    "        pass\n",
    "    \n",
    "    profit.append(sum(pnl)/len(pnl))         \n",
    "    \n",
    "print(classification_report(y_pred, y_test))\n",
    "print(\"The square root of Specificity and Sensitivity is {:.4f}%\".format(\n",
    "    math.sqrt(mean(specificity)*mean(sensitivity))*100)),\n",
    "print(\"The average P/L is {:.4f}\".format(mean(profit)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.16      0.16      0.16        96\n",
      "          -6       0.00      0.00      0.00        22\n",
      "          -5       0.00      0.00      0.00        34\n",
      "          -4       0.03      0.03      0.03        71\n",
      "          -3       0.06      0.06      0.06       246\n",
      "          -2       0.10      0.12      0.10       282\n",
      "           0       0.78      0.77      0.78      2648\n",
      "\n",
      "    accuracy                           0.62      3399\n",
      "   macro avg       0.16      0.16      0.16      3399\n",
      "weighted avg       0.63      0.62      0.62      3399\n",
      "\n",
      "The square root of Specificity and Sensitivity is 43.7086%\n",
      "The average P/L is -0.7517\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits = 10, test_size = 0.3, random_state = 4242)\n",
    "sss.get_n_splits(X_APP, y_BP)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 25)\n",
    "\n",
    "specificity = []\n",
    "sensitivity = []\n",
    "pnl = []\n",
    "profit = []\n",
    "\n",
    "for train_index, test_index in sss.split(X_APP, y_BP):\n",
    "    \"\"\" Splitting data and loading Tree Classifier \"\"\"\n",
    "    X_train, X_test = X_APP[train_index], X_APP[test_index]\n",
    "    y_train, y_test = y_BP[train_index], y_BP[test_index]\n",
    "    tree.fit(X_train, y_train)\n",
    "    y_pred = tree.predict(X_test)\n",
    "    \n",
    "    actually_good = 0\n",
    "    for i in y_test:\n",
    "        if i >= -1:\n",
    "            actually_good = actually_good + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_good = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] >= -1 and y_test[i] >=-1:\n",
    "            predict_actual_good = predict_actual_good + 1\n",
    "            pass\n",
    "        \n",
    "    goodness = predict_actual_good / actually_good\n",
    "    sensitivity.append(goodness)\n",
    "\n",
    "    actually_bad = 0\n",
    "    for i in y_test:\n",
    "        if i < -1:\n",
    "            actually_bad = actually_bad + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_bad = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] < -1 and y_test[i] <-1:\n",
    "            predict_actual_bad = predict_actual_bad + 1\n",
    "            pass\n",
    "    badness = predict_actual_bad / actually_bad\n",
    "    specificity.append(badness)\n",
    "    \n",
    "    \"\"\" Calculating average profit / loss \"\"\"\n",
    "    pnl = []\n",
    "    for i in range(len(y_pred)):\n",
    "        \"\"\" Assigning profit or loss values to predictions \"\"\"\n",
    "        if y_pred[i] == 0:\n",
    "            pnl.append(y_test[i])\n",
    "            pass\n",
    "        \n",
    "    profit.append(sum(pnl)/len(pnl))\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(\"The square root of Specificity and Sensitivity is {:.4f}%\".format(\n",
    "    math.sqrt(mean(specificity)*mean(sensitivity))*100)),\n",
    "print(\"The average P/L is {:.4f}\".format(mean(profit)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.11      0.19      0.14        52\n",
      "          -6       0.00      0.00      0.00         7\n",
      "          -5       0.00      0.00      0.00         8\n",
      "          -4       0.01      0.05      0.02        21\n",
      "          -3       0.01      0.03      0.02       115\n",
      "          -2       0.06      0.11      0.08       177\n",
      "           0       0.89      0.76      0.82      3019\n",
      "\n",
      "    accuracy                           0.69      3399\n",
      "   macro avg       0.15      0.16      0.15      3399\n",
      "weighted avg       0.80      0.69      0.74      3399\n",
      "\n",
      "The square root of Specificity and Sensitivity is 32.4066%\n",
      "The average P/L is -0.7649\n"
     ]
    }
   ],
   "source": [
    "sss_BP = StratifiedShuffleSplit(n_splits = 10, test_size = 0.3, random_state = 4242)\n",
    "sss_BP.get_n_splits(X_APP, y_BP)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 100, max_depth= 100)\n",
    "\n",
    "specificity = []\n",
    "sensitivity = []\n",
    "pnl = []\n",
    "profit = []\n",
    "\n",
    "for train_index, test_index in sss_BP.split(X_APP, y_BP):\n",
    "    \"\"\" Splitting data and loading Random Forest Regressor \"\"\"\n",
    "    X_train, X_test = X_APP[train_index], X_APP[test_index]\n",
    "    y_train, y_test = y_BP[train_index], y_BP[test_index]\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    \n",
    "    actually_good = 0\n",
    "    for i in y_test:\n",
    "        if i >= -1:\n",
    "            actually_good = actually_good + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_good = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] >= -1 and y_test[i] >=-1:\n",
    "            predict_actual_good = predict_actual_good + 1\n",
    "            pass\n",
    "    goodness = predict_actual_good / actually_good\n",
    "    sensitivity.append(goodness)\n",
    "\n",
    "    actually_bad = 0\n",
    "    for i in y_test:\n",
    "        if i < -1:\n",
    "            actually_bad = actually_bad + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_bad = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] < -1 and y_test[i] <-1:\n",
    "            predict_actual_bad = predict_actual_bad + 1\n",
    "            pass\n",
    "    badness = predict_actual_bad / actually_bad\n",
    "    specificity.append(badness)\n",
    "    \n",
    "    \"\"\" Calculating average profit / loss \"\"\"\n",
    "    pnl = []\n",
    "    for i in range(len(y_pred)):\n",
    "        \"\"\" Assigning profit or loss values to predictions \"\"\"\n",
    "        if y_pred[i] == 0:\n",
    "            pnl.append(y_test[i])\n",
    "            pass\n",
    "        \n",
    "    profit.append(sum(pnl)/len(pnl))\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(\"The square root of Specificity and Sensitivity is {:.4f}%\".format(\n",
    "    math.sqrt(mean(specificity)*mean(sensitivity))*100)),\n",
    "print(\"The average P/L is {:.4f}\".format(mean(profit)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPLICATION SCORING - P/L PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.00      0.00      0.00         0\n",
      "          -6       0.00      0.00      0.00         0\n",
      "          -5       0.00      0.00      0.00         0\n",
      "          -4       0.00      0.00      0.00         0\n",
      "          -3       0.00      0.00      0.00         0\n",
      "          -2       0.00      0.00      0.00         0\n",
      "           0       1.00      0.76      0.86      3399\n",
      "\n",
      "    accuracy                           0.76      3399\n",
      "   macro avg       0.14      0.11      0.12      3399\n",
      "weighted avg       1.00      0.76      0.86      3399\n",
      "\n",
      "The square root of Specificity and Sensitivity is 0.0000%\n",
      "The average P/L of this model is -0.0005%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=4242)\n",
    "sss.get_n_splits(X_APP, y_BP)\n",
    "\n",
    "specificity = []\n",
    "sensitivity = []\n",
    "pnl = []\n",
    "profit = []\n",
    "\n",
    "for train_index, test_index in sss.split(X_APP, y_BP):\n",
    "    \"\"\" Splitting data into 10 splits and applying Linear Regression \"\"\"\n",
    "    X_train, X_test = X_APP[train_index], X_APP[test_index]\n",
    "    y_train, y_test = y_BP[train_index], y_BP[test_index]\n",
    "    lr = LogisticRegression(C = 0.01, max_iter = 500, solver = \"saga\").fit(X_train,y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    pred_proba = lr.predict_proba(X_test)\n",
    "    recall = recall_score(y_pred, y_test, average = \"weighted\")\n",
    "    \n",
    "    \"\"\" Calculating sensitivity \"\"\"\n",
    "    actually_good = 0\n",
    "    for i in y_test:\n",
    "        if i >= -1:\n",
    "            actually_good = actually_good + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_good = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] >= -1 and y_test[i] >= -1:\n",
    "            predict_actual_good = predict_actual_good + 1\n",
    "            pass\n",
    "    goodness = predict_actual_good / actually_good\n",
    "    sensitivity.append(goodness)\n",
    "\n",
    "    \"\"\" Calculating Specificity\"\"\"\n",
    "    actually_bad = 0\n",
    "    for i in y_test:\n",
    "        if i < -1:\n",
    "            actually_bad = actually_bad + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_bad = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] < -1 and y_test[i] < -1:\n",
    "            predict_actual_bad = predict_actual_bad + 1\n",
    "            pass\n",
    "    badness = predict_actual_bad / actually_bad\n",
    "    specificity.append(badness)\n",
    "    \n",
    "    \"\"\" Calculating average profit / loss \"\"\"\n",
    "    pred_bucket = []\n",
    "    for i in range(len(y_pred)):\n",
    "        \"\"\" Assigning profit or loss values to predictions \"\"\"\n",
    "        if y_pred[i] == 0:\n",
    "            pred_bucket.append(y_test[i])\n",
    "            pass\n",
    "    \n",
    "    pnl = []\n",
    "    for i in range(len(pred_bucket)):\n",
    "        if pred_bucket[i] == -7:\n",
    "            pnl.append(-0.65),\n",
    "        elif pred_bucket[i] == -6:\n",
    "            pnl.append(-0.45),\n",
    "        elif pred_bucket[i] == -5:\n",
    "            pnl.append(-0.35),\n",
    "        elif pred_bucket[i] == -4:\n",
    "            pnl.append(-0.25),\n",
    "        elif pred_bucket[i] == -3:\n",
    "            pnl.append(-0.15),\n",
    "        elif pred_bucket[i] == -2:\n",
    "            pnl.append(0),\n",
    "        elif pred_bucket[i] == -1:\n",
    "            pnl.append(0.01),\n",
    "        elif pred_bucket[i] == 0:\n",
    "            pnl.append(0.03)\n",
    "        pass\n",
    "    profit.append(mean(pnl)/len(y_test)) \n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(\"The square root of Specificity and Sensitivity is {:.4f}%\".format(\n",
    "    math.sqrt(mean(specificity)*mean(sensitivity))*100)),\n",
    "print(\"The average P/L of this model is {:.4f}%\".format(mean(profit)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.17      0.17      0.17        92\n",
      "          -6       0.00      0.00      0.00        21\n",
      "          -5       0.00      0.00      0.00        34\n",
      "          -4       0.03      0.03      0.03        76\n",
      "          -3       0.06      0.06      0.06       247\n",
      "          -2       0.10      0.12      0.10       283\n",
      "           0       0.78      0.77      0.78      2646\n",
      "\n",
      "    accuracy                           0.62      3399\n",
      "   macro avg       0.16      0.16      0.16      3399\n",
      "weighted avg       0.63      0.62      0.62      3399\n",
      "\n",
      "The square root of Specificity and Sensitivity is 43.7906%\n",
      "The average P/L of this model is -0.0004%\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits = 10, test_size = 0.3, random_state = 4242)\n",
    "sss.get_n_splits(X_APP, y_BP)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 25)\n",
    "\n",
    "specificity = []\n",
    "sensitivity = []\n",
    "pnl = []\n",
    "profit = []\n",
    "\n",
    "for train_index, test_index in sss.split(X_APP, y_BP):\n",
    "    \"\"\" Splitting data and loading Tree Classifier \"\"\"\n",
    "    X_train, X_test = X_APP[train_index], X_APP[test_index]\n",
    "    y_train, y_test = y_BP[train_index], y_BP[test_index]\n",
    "    tree.fit(X_train, y_train)\n",
    "    y_pred = tree.predict(X_test)\n",
    "    \n",
    "    actually_good = 0\n",
    "    for i in y_test:\n",
    "        if i >= -1:\n",
    "            actually_good = actually_good + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_good = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] >= -1 and y_test[i] >=-1:\n",
    "            predict_actual_good = predict_actual_good + 1\n",
    "            pass\n",
    "        \n",
    "    goodness = predict_actual_good / actually_good\n",
    "    sensitivity.append(goodness)\n",
    "\n",
    "    actually_bad = 0\n",
    "    for i in y_test:\n",
    "        if i < -1:\n",
    "            actually_bad = actually_bad + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_bad = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] < -1 and y_test[i] <-1:\n",
    "            predict_actual_bad = predict_actual_bad + 1\n",
    "            pass\n",
    "    badness = predict_actual_bad / actually_bad\n",
    "    specificity.append(badness)\n",
    "    \n",
    "    \n",
    "    \"\"\" Calculating average profit / loss \"\"\"\n",
    "    pred_bucket = []\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        \"\"\" Assigning profit or loss values to predictions \"\"\"\n",
    "        if y_pred[i] == 0:\n",
    "            pred_bucket.append(y_test[i])\n",
    "            pass\n",
    "    \n",
    "    pnl = []\n",
    "    for i in range(len(pred_bucket)):\n",
    "        if pred_bucket[i] == -7:\n",
    "            pnl.append(-0.65),\n",
    "        elif pred_bucket[i] == -6:\n",
    "            pnl.append(-0.45),\n",
    "        elif pred_bucket[i] == -5:\n",
    "            pnl.append(-0.35),\n",
    "        elif pred_bucket[i] == -4:\n",
    "            pnl.append(-0.25),\n",
    "        elif pred_bucket[i] == -3:\n",
    "            pnl.append(-0.15),\n",
    "        elif pred_bucket[i] == -2:\n",
    "            pnl.append(0),\n",
    "        elif pred_bucket[i] == -1:\n",
    "            pnl.append(0.01),\n",
    "        elif pred_bucket[i] == 0:\n",
    "            pnl.append(0.03)\n",
    "        pass\n",
    "    profit.append(mean(pnl)/len(y_test)) \n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(\"The square root of Specificity and Sensitivity is {:.4f}%\".format(\n",
    "    math.sqrt(mean(specificity)*mean(sensitivity))*100)),\n",
    "print(\"The average P/L of this model is {:.4f}%\".format(mean(profit)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.14      0.19      0.16        68\n",
      "          -6       0.00      0.00      0.00        19\n",
      "          -5       0.00      0.00      0.00        14\n",
      "          -4       0.01      0.04      0.02        23\n",
      "          -3       0.02      0.04      0.03       156\n",
      "          -2       0.07      0.12      0.09       196\n",
      "           0       0.86      0.76      0.81      2923\n",
      "\n",
      "    accuracy                           0.67      3399\n",
      "   macro avg       0.16      0.17      0.16      3399\n",
      "weighted avg       0.75      0.67      0.71      3399\n",
      "\n",
      "The square root of Specificity and Sensitivity is 35.5506%\n",
      "The average P/L of this model is -0.0004%\n"
     ]
    }
   ],
   "source": [
    "sss_BP = StratifiedShuffleSplit(n_splits = 10, test_size = 0.3, random_state = 4242)\n",
    "sss_BP.get_n_splits(X_APP, y_BP)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 10, max_depth= 30)\n",
    "\n",
    "specificity = []\n",
    "sensitivity = []\n",
    "pnl = []\n",
    "profit = []\n",
    "\n",
    "for train_index, test_index in sss_BP.split(X_APP, y_BP):\n",
    "    \"\"\" Splitting data and loading Random Forest Regressor \"\"\"\n",
    "    X_train, X_test = X_APP[train_index], X_APP[test_index]\n",
    "    y_train, y_test = y_BP[train_index], y_BP[test_index]\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    \n",
    "    actually_good = 0\n",
    "    for i in y_test:\n",
    "        if i >= -1:\n",
    "            actually_good = actually_good + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_good = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] >= -1 and y_test[i] >=-1:\n",
    "            predict_actual_good = predict_actual_good + 1\n",
    "            pass\n",
    "    goodness = predict_actual_good / actually_good\n",
    "    sensitivity.append(goodness)\n",
    "\n",
    "    actually_bad = 0\n",
    "    for i in y_test:\n",
    "        if i < -1:\n",
    "            actually_bad = actually_bad + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_bad = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] < -1 and y_test[i] <-1:\n",
    "            predict_actual_bad = predict_actual_bad + 1\n",
    "            pass\n",
    "    badness = predict_actual_bad / actually_bad\n",
    "    specificity.append(badness)\n",
    "    \n",
    "    \"\"\" Calculating average profit / loss \"\"\"\n",
    "    pred_bucket = []\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        \"\"\" Assigning profit or loss values to predictions \"\"\"\n",
    "        if y_pred[i] == 0:\n",
    "            pred_bucket.append(y_test[i])\n",
    "            pass\n",
    "    \n",
    "    pnl = []\n",
    "    for i in range(len(pred_bucket)):\n",
    "        if pred_bucket[i] == -7:\n",
    "            pnl.append(-0.65),\n",
    "        elif pred_bucket[i] == -6:\n",
    "            pnl.append(-0.45),\n",
    "        elif pred_bucket[i] == -5:\n",
    "            pnl.append(-0.35),\n",
    "        elif pred_bucket[i] == -4:\n",
    "            pnl.append(-0.25),\n",
    "        elif pred_bucket[i] == -3:\n",
    "            pnl.append(-0.15),\n",
    "        elif pred_bucket[i] == -2:\n",
    "            pnl.append(0),\n",
    "        elif pred_bucket[i] == -1:\n",
    "            pnl.append(0.01),\n",
    "        elif pred_bucket[i] == 0:\n",
    "            pnl.append(0.03)\n",
    "        pass\n",
    "    profit.append(mean(pnl)/len(y_test)) \n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(\"The square root of Specificity and Sensitivity is {:.4f}%\".format(\n",
    "    math.sqrt(mean(specificity)*mean(sensitivity))*100)),\n",
    "print(\"The average P/L of this model is {:.4f}%\".format(mean(profit)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEAHVIOUR SCORING - ZERO ONE CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regerssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       1.00      0.89      0.94      3395\n",
      "\n",
      "    accuracy                           0.89      3399\n",
      "   macro avg       0.50      0.45      0.47      3399\n",
      "weighted avg       1.00      0.89      0.94      3399\n",
      "\n",
      "Accuracy Score: 89.3116%\n",
      "Square root of Sensitivity and Specificity: 6.5345%\n",
      "Average P/L: -2.9879%\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "specificity = []\n",
    "sensitivity = []\n",
    "pnl = []\n",
    "profit = []\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=4242)\n",
    "sss.get_n_splits(X_BS, y_01)\n",
    "\n",
    "for train_index, test_index in sss.split(X_BS, y_01):\n",
    "    \"\"\" Splitting data into 10 splits and bslying Logistic Regression \"\"\"\n",
    "    X_train, X_test = X_BS[train_index], X_BS[test_index]\n",
    "    y_train, y_test = y_01[train_index], y_01[test_index]\n",
    "    lr= LogisticRegression(C = 0.1, max_iter = 300).fit(X_train,y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    pnl = []\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        \"\"\" Assigning profit or loss values to predictions \"\"\"\n",
    "        if y_pred[i] == 1 and y_test[i] == 1:\n",
    "            pnl.append(0.02),\n",
    "        elif y_pred[i] == 1 and y_test[i] == 0:\n",
    "            pnl.append(-0.45),\n",
    "        pass\n",
    "    \n",
    "    \"\"\" evaluating the model \"\"\"\n",
    "    profit.append(mean(pnl))\n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity.append(tn / (tn+fp))\n",
    "    sensitivity.append(recall_score(y_test, y_pred))\n",
    "    \n",
    "ans = []\n",
    "for i in range(len(sensitivity)):\n",
    "    ans.append(math.sqrt(specificity[i]*sensitivity[i]))\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(\"Accuracy Score: {:.4f}%\".format(mean(accuracy)*100)),\n",
    "print(\"Square root of Sensitivity and Specificity: {:.4f}%\".format(mean(ans)*100)),\n",
    "print(\"Average P/L: {:.4f}%\".format(mean(profit)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81       354\n",
      "           1       0.98      0.98      0.98      3045\n",
      "\n",
      "    accuracy                           0.96      3399\n",
      "   macro avg       0.89      0.90      0.89      3399\n",
      "weighted avg       0.96      0.96      0.96      3399\n",
      "\n",
      "Accuracy Score: 95.7929%\n",
      "Square root of Sensitivity and Specificity: 87.5356%\n",
      "Average P/L: 0.7914%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 5)\n",
    "\n",
    "accuracy = []\n",
    "specificity = []\n",
    "sensitivity = []\n",
    "pnl = []\n",
    "profit = []\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=4242)\n",
    "sss.get_n_splits(X_BS, y_01)\n",
    "\n",
    "for train_index, test_index in sss.split(X_BS, y_01):\n",
    "    \"\"\" Splitting data and loading Tree Classifier \"\"\"\n",
    "    X_train, X_test = X_BS[train_index], X_BS[test_index]\n",
    "    y_train, y_test = y_01[train_index], y_01[test_index]\n",
    "    tree.fit(X_train, y_train)\n",
    "    y_pred = tree.predict(X_test)\n",
    "    pnl = []\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        \"\"\" Assigning profit or loss values to predictions \"\"\"\n",
    "        if y_pred[i] == 1 and y_test[i] == 1:\n",
    "            pnl.append(0.02),\n",
    "        elif y_pred[i] == 1 and y_test[i] == 0:\n",
    "            pnl.append(-0.45),\n",
    "        pass\n",
    "    \n",
    "    \"\"\" evaluating the model \"\"\"\n",
    "    profit.append(mean(pnl))\n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity.append(tn / (tn+fp))\n",
    "    sensitivity.append(recall_score(y_test, y_pred))\n",
    "    \n",
    "ans = []\n",
    "for i in range(len(sensitivity)):\n",
    "    ans.append(math.sqrt(specificity[i]*sensitivity[i]))\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(\"Accuracy Score: {:.4f}%\".format(mean(accuracy)*100)),\n",
    "print(\"Square root of Sensitivity and Specificity: {:.4f}%\".format(mean(ans)*100)),\n",
    "print(\"Average P/L: {:.4f}%\".format(mean(profit)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79       357\n",
      "           1       0.98      0.97      0.97      3042\n",
      "\n",
      "    accuracy                           0.95      3399\n",
      "   macro avg       0.88      0.88      0.88      3399\n",
      "weighted avg       0.96      0.95      0.96      3399\n",
      "\n",
      "Accuracy Score: 95.4604%\n",
      "Square root of Sensitivity and Specificity: 87.4463%\n",
      "Average P/L: 0.7961%\n"
     ]
    }
   ],
   "source": [
    "# the best \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "accuracy = []\n",
    "specificity = []\n",
    "sensitivity = []\n",
    "pnl = []\n",
    "profit = []\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=4242)\n",
    "sss.get_n_splits(X_BS, y_01)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators= 10, max_depth= 25)\n",
    "for train_index, test_index in sss.split(X_BS, y_01):\n",
    "    \"\"\" Splitting data and loading Random Forest Classifier \"\"\"\n",
    "    X_train, X_test = X_BS[train_index], X_BS[test_index]\n",
    "    y_train, y_test = y_01[train_index], y_01[test_index]\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    pnl = []\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        \"\"\" Assigning profit or loss values to predictions \"\"\"\n",
    "        if y_pred[i] == 1 and y_test[i] == 1:\n",
    "            pnl.append(0.02),\n",
    "        elif y_pred[i] == 1 and y_test[i] == 0:\n",
    "            pnl.append(-0.45),\n",
    "        pass\n",
    "    \n",
    "    \"\"\" evaluating the model \"\"\"\n",
    "    profit.append(mean(pnl))\n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity.append(tn / (tn+fp))\n",
    "    sensitivity.append(recall_score(y_test, y_pred))\n",
    "    \n",
    "ans = []\n",
    "for i in range(len(sensitivity)):\n",
    "    ans.append(math.sqrt(specificity[i]*sensitivity[i]))\n",
    "\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(\"Accuracy Score: {:.4f}%\".format(mean(accuracy)*100)),\n",
    "print(\"Square root of Sensitivity and Specificity: {:.4f}%\".format(mean(ans)*100)),\n",
    "print(\"Average P/L: {:.4f}%\".format(mean(profit)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEHAVIOURAL SCORING - BUCKET PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.01      0.08      0.02        13\n",
      "          -6       0.00      0.00      0.00         0\n",
      "          -5       0.00      0.00      0.00         0\n",
      "          -4       0.00      0.00      0.00         0\n",
      "          -3       0.00      0.00      0.00         3\n",
      "          -2       0.00      0.00      0.00         0\n",
      "           0       1.00      0.76      0.86      3383\n",
      "\n",
      "    accuracy                           0.76      3399\n",
      "   macro avg       0.14      0.12      0.13      3399\n",
      "weighted avg       0.99      0.76      0.86      3399\n",
      "\n",
      "The square root of Specificity and Sensitivity is 7.9025%\n",
      "The average P/L of this model is -0.7822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits = 10, test_size = 0.3, random_state = 42)\n",
    "sss.get_n_splits(X_BS, y_BP)\n",
    "\n",
    "specificity = []\n",
    "sensitivity = []\n",
    "pnl = []\n",
    "profit = []\n",
    "lr = LogisticRegression(C = 0.4,  max_iter = 200)\n",
    "\n",
    "for train_index, test_index in sss.split(X_BS, y_BP):\n",
    "    \"\"\" Splitting data and loading Random Forest Classifier \"\"\"\n",
    "    X_train, X_test = X_BS[train_index], X_BS[test_index]\n",
    "    y_train, y_test = y_BP[train_index], y_BP[test_index]\n",
    "    lr.fit(X_train,y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    pred_proba = lr.predict_proba(X_test)\n",
    "    \n",
    "    actually_good = 0\n",
    "    for i in y_test:\n",
    "        if i >= -1:\n",
    "            actually_good = actually_good + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_good = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] >= -1 and y_test[i] >=-1:\n",
    "            predict_actual_good = predict_actual_good + 1\n",
    "            pass\n",
    "    goodness = predict_actual_good / actually_good\n",
    "    sensitivity.append(goodness)\n",
    "\n",
    "    actually_bad = 0\n",
    "    for i in y_test:\n",
    "        if i < -1:\n",
    "            actually_bad = actually_bad + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_bad = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] < -1 and y_test[i] <-1:\n",
    "            predict_actual_bad = predict_actual_bad + 1\n",
    "            pass\n",
    "    badness = predict_actual_bad / actually_bad\n",
    "    specificity.append(badness)\n",
    "    \n",
    "    \"\"\" Calculating average profit / loss \"\"\"\n",
    "    pnl = []\n",
    "    for i in range(len(y_pred)):\n",
    "        \"\"\" Assigning profit or loss values to predictions \"\"\"\n",
    "        if y_pred[i] == 0:\n",
    "            pnl.append(y_test[i])\n",
    "        pass\n",
    "    \n",
    "    profit.append(sum(pnl)/len(pnl))\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(\"The square root of Specificity and Sensitivity is {:.4f}%\".format(\n",
    "    math.sqrt(mean(specificity)*mean(sensitivity))*100)),\n",
    "print(\"The average P/L of this model is {:.4f}\".format(mean(profit)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       1.00      1.00      1.00       213\n",
      "          -6       0.97      0.83      0.90        47\n",
      "          -5       0.94      0.89      0.91        89\n",
      "          -4       0.95      0.92      0.94       193\n",
      "          -3       0.90      0.97      0.93       529\n",
      "          -2       0.92      0.92      0.92       810\n",
      "           0       0.99      0.99      0.99      6050\n",
      "\n",
      "    accuracy                           0.98      7931\n",
      "   macro avg       0.95      0.93      0.94      7931\n",
      "weighted avg       0.98      0.98      0.98      7931\n",
      "\n",
      "The square root of Specificity and Sensitivity is 97.5789%\n",
      "The average P/L of this model is -0.0317\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "sss = StratifiedShuffleSplit(n_splits = 10, test_size = 0.7, random_state = 42)\n",
    "sss.get_n_splits(X_BS, y_BP)\n",
    "\n",
    "specificity = []\n",
    "sensitivity = []\n",
    "profit = []\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth = 10)\n",
    "\n",
    "for train_index, test_index in sss.split(X_BS, y_BP):\n",
    "    \"\"\" Splitting data and loading Random Forest Classifier \"\"\"\n",
    "    X_train, X_test = X_BS[train_index], X_BS[test_index]\n",
    "    y_train, y_test = y_BP[train_index], y_BP[test_index]\n",
    "    tree.fit(X_train, y_train)\n",
    "    y_pred = tree.predict(X_test)\n",
    "    pred_proba = tree.predict_proba(X_test)\n",
    "    \n",
    "    \"\"\"Calculating Sensitivity and Specitivity\"\"\"\n",
    "    actually_good = 0\n",
    "    for i in y_test:\n",
    "        if i >= -1:\n",
    "            actually_good = actually_good + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_good = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] >= -1 and y_test[i] >=-1:\n",
    "            predict_actual_good = predict_actual_good + 1\n",
    "            pass\n",
    "    goodness = predict_actual_good / actually_good\n",
    "    sensitivity.append(goodness)\n",
    "\n",
    "    actually_bad = 0\n",
    "    for i in y_test:\n",
    "        if i < -1:\n",
    "            actually_bad = actually_bad + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_bad = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] < -1 and y_test[i] <-1:\n",
    "            predict_actual_bad = predict_actual_bad + 1\n",
    "            pass\n",
    "    badness = predict_actual_bad / actually_bad\n",
    "    specificity.append(badness)\n",
    "    \n",
    "\n",
    "    \"\"\" Calculating average profit / loss \"\"\"\n",
    "    pnl = []\n",
    "    for i in range(len(y_pred)):\n",
    "        \"\"\" Assigning profit or loss values to predictions \"\"\"\n",
    "        if y_pred[i] == 0:\n",
    "            pnl.append(y_test[i])\n",
    "            pass\n",
    "        \n",
    "    profit.append(sum(pnl)/len(pnl))\n",
    "    \n",
    "print(classification_report(y_pred, y_test))\n",
    "print(\"The square root of Specificity and Sensitivity is {:.4f}%\".format(\n",
    "    math.sqrt(mean(specificity)*mean(sensitivity))*100)),\n",
    "print(\"The average P/L of this model is {:.4f}\".format(mean(profit)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.97      0.95      0.96        94\n",
      "          -6       0.53      0.90      0.67        10\n",
      "          -5       0.72      0.87      0.79        30\n",
      "          -4       0.93      0.89      0.91        83\n",
      "          -3       0.91      0.98      0.94       225\n",
      "          -2       0.95      0.96      0.96       342\n",
      "           0       1.00      0.99      0.99      2615\n",
      "\n",
      "    accuracy                           0.98      3399\n",
      "   macro avg       0.86      0.93      0.89      3399\n",
      "weighted avg       0.98      0.98      0.98      3399\n",
      "\n",
      "The square root of Specificity and Sensitivity is 97.7515%\n",
      "The average P/L of this model is -0.0368\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits = 10, test_size = 0.3, random_state = 42)\n",
    "sss.get_n_splits(X_BS, y_BP)\n",
    "\n",
    "specificity = []\n",
    "sensitivity = []\n",
    "pnl = []\n",
    "profit = []\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators= 10, criterion = \"entropy\", max_depth = 10)\n",
    "\n",
    "for train_index, test_index in sss.split(X_BS, y_BP):\n",
    "    \"\"\" Splitting data and loading Random Forest Classifier \"\"\"\n",
    "    X_train, X_test = X_BS[train_index], X_BS[test_index]\n",
    "    y_train, y_test = y_BP[train_index], y_BP[test_index]\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    pred_proba = rf.predict_proba(X_test)\n",
    "    \n",
    "    \"\"\"Calculating Sensitivity and Specitivity\"\"\"\n",
    "    actually_good = 0\n",
    "    for i in y_test:\n",
    "        if i >= -1:\n",
    "            actually_good = actually_good + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_good = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] >= -1 and y_test[i] >=-1:\n",
    "            predict_actual_good = predict_actual_good + 1\n",
    "            pass\n",
    "    goodness = predict_actual_good / actually_good\n",
    "    sensitivity.append(goodness)\n",
    "\n",
    "    actually_bad = 0\n",
    "    for i in y_test:\n",
    "        if i < -1:\n",
    "            actually_bad = actually_bad + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_bad = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] < -1 and y_test[i] <-1:\n",
    "            predict_actual_bad = predict_actual_bad + 1\n",
    "            pass\n",
    "    badness = predict_actual_bad / actually_bad\n",
    "    specificity.append(badness)\n",
    "    \n",
    "    \"\"\" Calculating average profit / loss \"\"\"\n",
    "    pnl = []\n",
    "    for i in range(len(y_pred)):\n",
    "        \"\"\" Assigning profit or loss values to predictions \"\"\"\n",
    "        if y_pred[i] == 0:\n",
    "            pnl.append(y_test[i])\n",
    "            pass\n",
    "        \n",
    "    profit.append(sum(pnl)/len(pnl))\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(\"The square root of Specificity and Sensitivity is {:.4f}%\".format(\n",
    "    math.sqrt(mean(specificity)*mean(sensitivity))*100)),\n",
    "print(\"The average P/L of this model is {:.4f}\".format(mean(profit)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEHAVIOURAL SCORING - P/L PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.01      0.08      0.02        13\n",
      "          -6       0.00      0.00      0.00         0\n",
      "          -5       0.00      0.00      0.00         0\n",
      "          -4       0.00      0.00      0.00         0\n",
      "          -3       0.00      0.00      0.00         3\n",
      "          -2       0.00      0.00      0.00         0\n",
      "           0       1.00      0.76      0.86      3383\n",
      "\n",
      "    accuracy                           0.76      3399\n",
      "   macro avg       0.14      0.12      0.13      3399\n",
      "weighted avg       0.99      0.76      0.86      3399\n",
      "\n",
      "The square root of Specificity and Sensitivity is 7.9025%\n",
      "The average P/L of this model is -0.0005%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeye\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits = 10, test_size = 0.3, random_state = 42)\n",
    "sss.get_n_splits(X_BS, y_BP)\n",
    "\n",
    "specificity = []\n",
    "sensitivity = []\n",
    "pnl = []\n",
    "profit = []\n",
    "\n",
    "lr = LogisticRegression(C = 0.4, max_iter = 200)\n",
    "\n",
    "for train_index, test_index in sss.split(X_BS, y_BP):\n",
    "    \"\"\" Splitting data and loading Random Forest Classifier \"\"\"\n",
    "    X_train, X_test = X_BS[train_index], X_BS[test_index]\n",
    "    y_train, y_test = y_BP[train_index], y_BP[test_index]\n",
    "    lr.fit(X_train,y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    pred_proba = lr.predict_proba(X_test)\n",
    "    \n",
    "    \"\"\" Calculating sensitivity and specitivity\"\"\"\n",
    "    actually_good = 0\n",
    "    for i in y_test:\n",
    "        if i >= -1:\n",
    "            actually_good = actually_good + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_good = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] >= -1 and y_test[i] >=-1:\n",
    "            predict_actual_good = predict_actual_good + 1\n",
    "            pass\n",
    "    goodness = predict_actual_good / actually_good\n",
    "    sensitivity.append(goodness)\n",
    "\n",
    "    actually_bad = 0\n",
    "    for i in y_test:\n",
    "        if i < -1:\n",
    "            actually_bad = actually_bad + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_bad = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] < -1 and y_test[i] <-1:\n",
    "            predict_actual_bad = predict_actual_bad + 1\n",
    "            pass\n",
    "    badness = predict_actual_bad / actually_bad\n",
    "    specificity.append(badness)\n",
    "    \n",
    "    \"\"\" Calculating average profit / loss \"\"\"\n",
    "    pred_bucket = []\n",
    "    for i in range(len(y_pred)):\n",
    "        \"\"\" Assigning profit or loss values to predictions \"\"\"\n",
    "        if y_pred[i] == 0:\n",
    "            pred_bucket.append(y_test[i])\n",
    "            pass\n",
    "    \n",
    "    pnl = []\n",
    "    for i in range(len(pred_bucket)):\n",
    "        if pred_bucket[i] == -7:\n",
    "            pnl.append(-0.65),\n",
    "        elif pred_bucket[i] == -6:\n",
    "            pnl.append(-0.45),\n",
    "        elif pred_bucket[i] == -5:\n",
    "            pnl.append(-0.35),\n",
    "        elif pred_bucket[i] == -4:\n",
    "            pnl.append(-0.25),\n",
    "        elif pred_bucket[i] == -3:\n",
    "            pnl.append(-0.15),\n",
    "        elif pred_bucket[i] == -2:\n",
    "            pnl.append(0),\n",
    "        elif pred_bucket[i] == -1:\n",
    "            pnl.append(0.01),\n",
    "        elif pred_bucket[i] == 0:\n",
    "            pnl.append(0.03)\n",
    "        pass\n",
    "    profit.append(mean(pnl)/len(y_test)) \n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(\"The square root of Specificity and Sensitivity is {:.4f}%\".format(\n",
    "    math.sqrt(mean(specificity)*mean(sensitivity))*100)),\n",
    "print(\"The average P/L of this model is {:.4f}%\".format(mean(profit)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       1.00      1.00      1.00        92\n",
      "          -6       0.94      1.00      0.97        16\n",
      "          -5       0.94      0.94      0.94        36\n",
      "          -4       0.93      0.95      0.94        78\n",
      "          -3       0.91      0.92      0.92       240\n",
      "          -2       0.91      0.92      0.91       345\n",
      "           0       0.99      0.99      0.99      2592\n",
      "\n",
      "    accuracy                           0.98      3399\n",
      "   macro avg       0.95      0.96      0.95      3399\n",
      "weighted avg       0.98      0.98      0.98      3399\n",
      "\n",
      "The square root of Specificity and Sensitivity is 97.6132%\n",
      "The average P/L of this model is 0.0008%\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits = 10, test_size = 0.3, random_state = 42)\n",
    "sss.get_n_splits(X_BS, y_BP)\n",
    "\n",
    "specificity = []\n",
    "sensitivity = []\n",
    "pnl = []\n",
    "profit = []\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth = 70)\n",
    "\n",
    "for train_index, test_index in sss.split(X_BS, y_BP):\n",
    "    \"\"\" Splitting data and loading Random Forest Classifier \"\"\"\n",
    "    X_train, X_test = X_BS[train_index], X_BS[test_index]\n",
    "    y_train, y_test = y_BP[train_index], y_BP[test_index]\n",
    "    tree.fit(X_train, y_train)\n",
    "    y_pred = tree.predict(X_test)\n",
    "    \n",
    "    \"\"\"Calculating Sensitivity and Specitivity\"\"\"\n",
    "    actually_good = 0\n",
    "    for i in y_test:\n",
    "        if i >= -1:\n",
    "            actually_good = actually_good + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_good = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] >= -1 and y_test[i] >=-1:\n",
    "            predict_actual_good = predict_actual_good + 1\n",
    "            pass\n",
    "    goodness = predict_actual_good / actually_good\n",
    "    sensitivity.append(goodness)\n",
    "\n",
    "    actually_bad = 0\n",
    "    for i in y_test:\n",
    "        if i < -1:\n",
    "            actually_bad = actually_bad + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_bad = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] < -1 and y_test[i] <-1:\n",
    "            predict_actual_bad = predict_actual_bad + 1\n",
    "            pass\n",
    "    badness = predict_actual_bad / actually_bad\n",
    "    specificity.append(badness)\n",
    "    \n",
    "    \"\"\" Calculating average profit / loss \"\"\"\n",
    "    pred_bucket = []\n",
    "    for i in range(len(y_pred)):\n",
    "        \"\"\" Assigning profit or loss values to predictions \"\"\"\n",
    "        if y_pred[i] == 0:\n",
    "            pred_bucket.append(y_test[i])\n",
    "            pass\n",
    "    \n",
    "    pnl = []\n",
    "    for i in range(len(pred_bucket)):\n",
    "        if pred_bucket[i] == -7:\n",
    "            pnl.append(-0.65),\n",
    "        elif pred_bucket[i] == -6:\n",
    "            pnl.append(-0.45),\n",
    "        elif pred_bucket[i] == -5:\n",
    "            pnl.append(-0.35),\n",
    "        elif pred_bucket[i] == -4:\n",
    "            pnl.append(-0.25),\n",
    "        elif pred_bucket[i] == -3:\n",
    "            pnl.append(-0.15),\n",
    "        elif pred_bucket[i] == -2:\n",
    "            pnl.append(0),\n",
    "        elif pred_bucket[i] == -1:\n",
    "            pnl.append(0.01),\n",
    "        elif pred_bucket[i] == 0:\n",
    "            pnl.append(0.03)\n",
    "        pass\n",
    "    profit.append(mean(pnl)/len(y_test))\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(\"The square root of Specificity and Sensitivity is {:.4f}%\".format(\n",
    "    math.sqrt(mean(specificity)*mean(sensitivity))*100)),\n",
    "print(\"The average P/L of this model is {:.4f}%\".format(mean(profit)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -7       0.97      0.96      0.96        93\n",
      "          -6       0.24      0.57      0.33         7\n",
      "          -5       0.67      0.67      0.67        36\n",
      "          -4       0.89      0.88      0.88        81\n",
      "          -3       0.90      0.95      0.93       231\n",
      "          -2       0.93      0.96      0.95       336\n",
      "           0       1.00      0.99      0.99      2615\n",
      "\n",
      "    accuracy                           0.97      3399\n",
      "   macro avg       0.80      0.85      0.82      3399\n",
      "weighted avg       0.98      0.97      0.98      3399\n",
      "\n",
      "The square root of Specificity and Sensitivity is 97.7081%\n",
      "The average P/L of this model is 0.0008%\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits = 10, test_size = 0.3, random_state = 42)\n",
    "sss.get_n_splits(X_BS, y_BP)\n",
    "\n",
    "specificity = []\n",
    "sensitivity = []\n",
    "pnl = []\n",
    "profit = []\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators= 10, criterion = \"entropy\", max_depth = 10)\n",
    "\n",
    "for train_index, test_index in sss.split(X_BS, y_BP):\n",
    "    \"\"\" Splitting data and loading Random Forest Classifier \"\"\"\n",
    "    X_train, X_test = X_BS[train_index], X_BS[test_index]\n",
    "    y_train, y_test = y_BP[train_index], y_BP[test_index]\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    pred_proba = rf.predict_proba(X_test)\n",
    "    \n",
    "    actually_good = 0\n",
    "    for i in y_test:\n",
    "        if i >= -1:\n",
    "            actually_good = actually_good + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_good = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] >= -1 and y_test[i] >=-1:\n",
    "            predict_actual_good = predict_actual_good + 1\n",
    "            pass\n",
    "    goodness = predict_actual_good / actually_good\n",
    "    sensitivity.append(goodness)\n",
    "\n",
    "    actually_bad = 0\n",
    "    for i in y_test:\n",
    "        if i < -1:\n",
    "            actually_bad = actually_bad + 1\n",
    "            pass\n",
    "        \n",
    "    predict_actual_bad = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] < -1 and y_test[i] <-1:\n",
    "            predict_actual_bad = predict_actual_bad + 1\n",
    "            pass\n",
    "    badness = predict_actual_bad / actually_bad\n",
    "    specificity.append(badness)\n",
    "    \n",
    "   \n",
    "    pred_bucket = []\n",
    "    for i in range(len(y_pred)):\n",
    "        \"\"\" Assigning profit or loss values to predictions \"\"\"\n",
    "        if y_pred[i] == 0:\n",
    "            pred_bucket.append(y_test[i])\n",
    "            pass\n",
    "    \n",
    "    pnl = []\n",
    "    for i in range(len(pred_bucket)):\n",
    "        if pred_bucket[i] == -7:\n",
    "            pnl.append(-0.65),\n",
    "        elif pred_bucket[i] == -6:\n",
    "            pnl.append(-0.45),\n",
    "        elif pred_bucket[i] == -5:\n",
    "            pnl.append(-0.35),\n",
    "        elif pred_bucket[i] == -4:\n",
    "            pnl.append(-0.25),\n",
    "        elif pred_bucket[i] == -3:\n",
    "            pnl.append(-0.15),\n",
    "        elif pred_bucket[i] == -2:\n",
    "            pnl.append(0),\n",
    "        elif pred_bucket[i] == -1:\n",
    "            pnl.append(0.01),\n",
    "        elif pred_bucket[i] == 0:\n",
    "            pnl.append(0.03)\n",
    "        pass\n",
    "    profit.append(mean(pnl)/len(y_test))\n",
    "    \n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(\"The square root of Specificity and Sensitivity is {:.4f}%\".format(\n",
    "    math.sqrt(mean(specificity)*mean(sensitivity))*100)),\n",
    "print(\"The average P/L of this model is {:.4f}%\".format(mean(profit)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
